[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one/0 [executing] active: 
  shard-one/1 [executing] active: Primary
  shard-two/0 [executing] active: Primary
  config-server/0 [executing] waiting: Waiting to sync passwords across the cluster
  config-server/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-3
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-4
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-5
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  s3-integrator/0 [idle] active: 
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] waiting: agent initialising
  config-server-new/1 [executing] maintenance: installing MongoDB
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: starting MongoDB
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] maintenance: starting MongoDB
  shard-one-new/1 [executing] maintenance: starting MongoDB
  shard-two-new/0 [executing] maintenance: starting MongoDB
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [idle] active: 
  shard-two-new/0 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] maintenance: Adding shard to config-server
  shard-two-new/0 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] waiting: waiting to sync s3 configurations.
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: Primary
  shard-one-new/1 [idle] active: 
  shard-two-new/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [executing] active: Primary
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: Primary
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-22T02:07:14Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] active: Primary
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:28:02Z

App                Version  Status  Scale  Charm          Channel      Rev  Exposed  Message
config-server-new  6.0.6    active      2  mongodb                       3  no       
s3-integrator               active      1  s3-integrator  latest/edge  133  no       
shard-one-new      6.0.6    active      2  mongodb                       4  no       
shard-two-new      6.0.6    active      1  mongodb                       5  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-new/0   active    idle   6        10.160.179.183  27017-27018/tcp  
config-server-new/1*  active    idle   7        10.160.179.48   27017-27018/tcp  Primary
s3-integrator/0*      active    idle   5        10.160.179.53                    
shard-one-new/0*      active    idle   8        10.160.179.184  27017/tcp        Primary
shard-one-new/1       active    idle   9        10.160.179.252  27017/tcp        
shard-two-new/0*      active    idle   10       10.160.179.24   27017/tcp        Primary

Machine  State    Address         Inst id         Base          AZ  Message
5        started  10.160.179.53   juju-9008a0-5   ubuntu@22.04      Running
6        started  10.160.179.183  juju-9008a0-6   ubuntu@22.04      Running
7        started  10.160.179.48   juju-9008a0-7   ubuntu@22.04      Running
8        started  10.160.179.184  juju-9008a0-8   ubuntu@22.04      Running
9        started  10.160.179.252  juju-9008a0-9   ubuntu@22.04      Running
10       started  10.160.179.24   juju-9008a0-10  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-0: 01:30:20 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:30:20 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-0: 01:30:20 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:30:21 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:30:21 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-1: 01:30:21 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:30:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:30:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:30:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:30:32 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:30:32 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:30:32 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-5: 01:30:38 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:30:38 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-s3-integrator-0: 01:30:38 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:30:38 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:30:38 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:30:38 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-0: 01:30:42 ERROR unit.config-server/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:30:42 ERROR unit.config-server/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:30:47 ERROR unit.config-server/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:30:47 ERROR unit.config-server/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:30:51 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:30:52 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:30:57 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:30:57 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:30:57 ERROR unit.shard-one/0.juju-log This operation (update_relation_data()) can only be performed by the leader unit
unit-shard-one-0: 01:30:59 ERROR unit.shard-one/0.juju-log Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-shard-two-0: 01:30:59 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:30:59 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:31:00 ERROR unit.shard-one/0.juju-log database-peers:2: Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-shard-one-1: 01:32:34 ERROR unit.shard-one/1.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b92931dd752d6d7deb881e, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.122', 27017) server_type: RSSecondary, rtt: 0.0015558009981759824>, <ServerDescription ('10.160.179.60', 27017) server_type: RSSecondary, rtt: 0.000696316004905384>]>
unit-shard-one-1: 01:32:38 ERROR unit.shard-one/1.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b92935dd752d6d7deb881f, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.122', 27017) server_type: RSSecondary, rtt: 0.0012467250053305179>, <ServerDescription ('10.160.179.60', 27017) server_type: RSSecondary, rtt: 0.0008374430035473779>]>
unit-shard-one-1: 01:33:17 ERROR unit.shard-one/1.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b9295c192e9d7b4f042999, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.122', 27017) server_type: RSSecondary, rtt: 0.0016269450061372481>, <ServerDescription ('10.160.179.60', 27017) server_type: RSSecondary, rtt: 0.0009566790031385608>]>
unit-shard-one-1: 01:33:21 ERROR unit.shard-one/1.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b92960192e9d7b4f04299a, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.122', 27017) server_type: RSSecondary, rtt: 0.0006660790022579022>, <ServerDescription ('10.160.179.60', 27017) server_type: RSSecondary, rtt: 0.0006489759980468079>]>
unit-shard-one-1: 01:33:25 ERROR unit.shard-one/1.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b92964192e9d7b4f04299b, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.122', 27017) server_type: RSSecondary, rtt: 0.0010167310028919019>, <ServerDescription ('10.160.179.60', 27017) server_type: RSSecondary, rtt: 0.0008542430005036294>]>
unit-shard-one-1: 01:36:58 ERROR unit.shard-one/1.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-1: 01:37:00 ERROR unit.shard-one/1.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-1: 01:37:02 ERROR unit.shard-one/1.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-config-server-0: 01:40:29 ERROR unit.config-server/0.juju-log cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.160.179.113:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-0: 01:40:29 ERROR unit.config-server/0.juju-log Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.160.179.113:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-0: 02:12:21 ERROR unit.config-server/0.juju-log config-server:9: cannot remove shard shard-two from cluster, another shard is draining
unit-config-server-0: 02:12:21 ERROR unit.config-server/0.juju-log config-server:9: Deferring _on_relation_event for shards interface since: error=cannot remove shard shard-two from cluster, another shard is draining
machine-2: 02:12:59 ERROR juju.api.watcher error trying to stop watcher: websocket: close sent
machine-7: 02:16:05 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:16:05 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-1: 02:16:05 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-6: 02:16:10 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:16:10 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-0: 02:16:10 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-8: 02:16:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:16:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-0: 02:16:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-10: 02:16:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-10: 02:16:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-new-0: 02:16:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-9: 02:16:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:16:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-1: 02:16:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-1: 02:16:25 ERROR unit.config-server-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:16:25 ERROR unit.config-server-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:16:37 ERROR unit.config-server-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:16:37 ERROR unit.config-server-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:16:38 ERROR unit.shard-two-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:16:38 ERROR unit.shard-two-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:16:38 ERROR unit.shard-one-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:16:38 ERROR unit.shard-one-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:16:38 ERROR unit.shard-one-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:16:38 ERROR unit.shard-one-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:18:46 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b93404b48dcca40aa759cc, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0005572230002144352>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0005554090021178126>]>
unit-shard-one-new-0: 02:18:50 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b93409b48dcca40aa759cd, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0011180219953530468>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0007320419972529635>]>
unit-shard-one-new-0: 02:18:54 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b9340db48dcca40aa759ce, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0007588430016767234>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0006417120021069422>]>
unit-shard-one-new-0: 02:19:32 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b9343270d27dbca78cfdf6, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0007718179986113682>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0009406370008946396>]>
unit-shard-one-new-0: 02:19:36 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b9343770d27dbca78cfdf7, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0005697270025848411>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0005709380056941882>]>
unit-shard-one-new-0: 02:19:40 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b9343b70d27dbca78cfdf8, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.160.179.184', 27017) server_type: RSSecondary, rtt: 0.0005897250011912547>, <ServerDescription ('10.160.179.252', 27017) server_type: RSSecondary, rtt: 0.0008541540009900928>]>
unit-config-server-new-1: 02:26:40 ERROR unit.config-server-new/1.juju-log Restore failed: Cannot restore backup, 'remap-pattern' must be set.

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...