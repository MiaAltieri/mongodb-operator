[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-one/0 [executing] active: Primary
  shard-one/1 [executing] active: 
  shard-two/0 [executing] active: Primary
  config-server/0 [executing] active: 
  config-server/1 [executing] active: Primary
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server/1 [idle] active: Primary
[32mINFO    [0m juju.model:model.py:2097 Deploying local:jammy/mongodb-3
[32mINFO    [0m juju.model:model.py:2097 Deploying local:jammy/mongodb-4
[32mINFO    [0m juju.model:model.py:2097 Deploying local:jammy/mongodb-5
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  s3-integrator/0 [idle] active: 
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] maintenance: installing MongoDB
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: agent initialising
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: agent initialising
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [allocating] waiting: agent initialising
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [executing] maintenance: installing MongoDB
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/1 [executing] maintenance: installing MongoDB
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/1 [allocating] waiting: agent initialising
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] maintenance: installing MongoDB
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] waiting: waiting to sync s3 configurations.
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] waiting: Waiting for secrets from config-server
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
  shard-two-new/0 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] maintenance: Adding shard shard-one-new to config-server
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] waiting: Waiting for secrets from config-server
  shard-one-new/1 [executing] waiting: Waiting for secrets from config-server
  shard-two-new/0 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [idle] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [idle] waiting: Waiting for secrets from config-server
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
  shard-two-new/0 [executing] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/1 [idle] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [idle] waiting: Waiting for secrets from config-server
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
  shard-two-new/0 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [idle] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [executing] active: Primary
  shard-one-new/1 [executing] waiting: Waiting for secrets from config-server
  shard-two-new/0 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/1 [idle] waiting: waiting to sync s3 configurations.
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
  shard-two-new/0 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] waiting: waiting to sync s3 configurations.
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-one-new/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-one-new/0 [executing] active: Primary
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: Primary
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-01-15T02:06:36Z'
  config-server-new/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-01-15T02:06:36Z'
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:26:35Z

App                Version  Status  Scale  Charm          Channel      Rev  Exposed  Message
config-server-new           active      2  mongodb                       3  no       
s3-integrator               active      1  s3-integrator  latest/edge   99  no       
shard-one-new               active      2  mongodb                       4  no       
shard-two-new               active      1  mongodb                       5  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-new/0*  active    idle   6        10.176.96.89    27017-27018/tcp  Primary
config-server-new/1   active    idle   7        10.176.96.142   27017-27018/tcp  
s3-integrator/0*      active    idle   5        10.176.96.12                     
shard-one-new/0*      active    idle   8        10.176.96.132   27017/tcp        Primary
shard-one-new/1       active    idle   9        10.176.96.130   27017/tcp        
shard-two-new/0*      active    idle   10       10.176.96.152   27017/tcp        Primary

Machine  State    Address        Inst id         Base          AZ  Message
5        started  10.176.96.12   juju-1e96a9-5   ubuntu@22.04      Running
6        started  10.176.96.89   juju-1e96a9-6   ubuntu@22.04      Running
7        started  10.176.96.142  juju-1e96a9-7   ubuntu@22.04      Running
8        started  10.176.96.132  juju-1e96a9-8   ubuntu@22.04      Running
9        started  10.176.96.130  juju-1e96a9-9   ubuntu@22.04      Running
10       started  10.176.96.152  juju-1e96a9-10  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-1: 01:44:34 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:44:34 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-1: 01:44:34 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:44:51 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:44:51 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:44:51 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-1: 01:45:02 ERROR unit.config-server/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:45:02 ERROR unit.config-server/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-4: 01:45:10 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:45:10 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:45:10 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-1: 01:45:21 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:45:21 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:45:40 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:45:40 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-5: 01:45:49 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:45:49 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-s3-integrator-0: 01:45:49 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-1: 01:45:58 ERROR unit.config-server/1.juju-log _on_secret_remove: Secret secret:cu3h6dq1geasu4t1t370 seems to have no observers, could be removed
machine-0: 01:46:05 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:46:05 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-0: 01:46:05 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-1: 01:46:15 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu3h6ia1geasu4t1t37g seems to have no observers, could be removed
machine-2: 01:46:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:46:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:46:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-0: 01:46:28 ERROR unit.config-server/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:46:28 ERROR unit.config-server/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:46:33 ERROR unit.shard-two/0.juju-log _on_secret_remove: Secret secret:cu3h6ni1geasu4t1t380 seems to have no observers, could be removed
unit-shard-one-0: 01:46:47 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:46:47 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:48:20 ERROR unit.config-server/1.juju-log config-server:8: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-config-server-1: 01:48:52 ERROR unit.config-server/1.juju-log config-server:8: Failed to add shard shard-one to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1736905730, 2), \'signature\': {\'hash\': b\'\\xf1O\\xa1\\xa5\\xb15\\x89I\\x1a\\x1a\\xfaL,\\xd3\\xd8\\x08\\xbd`\\x02L\', \'keyId\': 7459952490541219863}}, \'operationTime\': Timestamp(1736905730, 2)}')
unit-config-server-1: 01:48:52 ERROR unit.config-server/1.juju-log config-server:8: Failed to add shard-one to cluster
unit-config-server-1: 01:48:52 ERROR unit.config-server/1.juju-log config-server:8: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1736905730, 2), \'signature\': {\'hash\': b\'\\xf1O\\xa1\\xa5\\xb15\\x89I\\x1a\\x1a\\xfaL,\\xd3\\xd8\\x08\\xbd`\\x02L\', \'keyId\': 7459952490541219863}}, \'operationTime\': Timestamp(1736905730, 2)}')
unit-config-server-1: 01:49:06 ERROR unit.config-server/1.juju-log config-server:8: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-shard-one-1: 01:49:19 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu3h6ia1geasu4t1t37g seems to have no observers, could be removed
unit-shard-two-0: 01:49:37 ERROR unit.shard-two/0.juju-log _on_secret_remove: Secret secret:cu3h6ni1geasu4t1t380 seems to have no observers, could be removed
unit-shard-one-1: 01:52:18 ERROR unit.shard-one/1.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-1: 01:52:20 ERROR unit.shard-one/1.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-1: 01:52:21 ERROR unit.shard-one/1.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-config-server-1: 01:56:18 ERROR unit.config-server/1.juju-log _on_secret_remove: Secret secret:cu3h6dq1geasu4t1t370 seems to have no observers, could be removed
unit-shard-two-0: 01:56:20 ERROR unit.shard-two/0.juju-log _on_secret_remove: Secret secret:cu3h6ni1geasu4t1t380 seems to have no observers, could be removed
unit-config-server-0: 02:00:46 ERROR unit.config-server/0.juju-log Failed to get pbm status: 'name'
unit-config-server-1: 02:05:46 ERROR unit.config-server/1.juju-log _on_secret_remove: Secret secret:cu3h6dq1geasu4t1t370 seems to have no observers, could be removed
unit-shard-two-0: 02:05:46 ERROR unit.shard-two/0.juju-log _on_secret_remove: Secret secret:cu3h6ni1geasu4t1t380 seems to have no observers, could be removed
unit-shard-one-1: 02:05:46 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu3h6ia1geasu4t1t37g seems to have no observers, could be removed
unit-config-server-1: 02:05:46 ERROR unit.config-server/1.juju-log _on_secret_remove: Secret secret:cu3h87i1geasu4t1t390 seems to have no observers, could be removed
unit-shard-one-1: 02:05:47 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu3h6ia1geasu4t1t37g seems to have no observers, could be removed
unit-config-server-1: 02:05:47 ERROR unit.config-server/1.juju-log _on_secret_remove: Secret secret:cu3h7si1geasu4t1t38g seems to have no observers, could be removed
machine-3: 02:10:17 ERROR juju.api.watcher error trying to stop watcher: websocket: close sent
machine-6: 02:16:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:16:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-0: 02:16:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-0: 02:16:37 ERROR unit.config-server-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:16:37 ERROR unit.config-server-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-8: 02:16:53 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:16:53 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-0: 02:16:54 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-10: 02:17:10 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-10: 02:17:10 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-new-0: 02:17:10 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-new-0: 02:17:16 ERROR unit.shard-one-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:17:16 ERROR unit.shard-one-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:17:26 ERROR unit.config-server-new/0.juju-log _on_secret_remove: Secret secret:cu3hl7a1geasu4t1t39g seems to have no observers, could be removed
unit-shard-two-new-0: 02:17:31 ERROR unit.shard-two-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:17:31 ERROR unit.shard-two-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-7: 02:17:36 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:17:36 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-1: 02:17:36 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-1: 02:17:57 ERROR unit.config-server-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:17:57 ERROR unit.config-server-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:18:03 ERROR unit.shard-one-new/0.juju-log _on_secret_remove: Secret secret:cu3hlh21geasu4t1t3a0 seems to have no observers, could be removed
unit-shard-two-new-0: 02:18:17 ERROR unit.shard-two-new/0.juju-log _on_secret_remove: Secret secret:cu3hlkq1geasu4t1t3ag seems to have no observers, could be removed
machine-9: 02:18:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:18:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-1: 02:18:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-new-1: 02:18:50 ERROR unit.shard-one-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:18:50 ERROR unit.shard-one-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:19:57 ERROR unit.config-server-new/0.juju-log config-server:17: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-config-server-new-0: 02:20:04 ERROR unit.config-server-new/0.juju-log s3-credentials:16: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-config-server-new-0: 02:20:56 ERROR unit.config-server-new/0.juju-log config-server:17: Failed to add shard shard-one-new to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one-new, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one-new\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1736907656, 2), \'signature\': {\'hash\': b\'\\xa3 \\xb3FY*\\xa3\\x88"\\xe3][\\xd8\\x0bIw\\xf1\\xcd\\\\D\', \'keyId\': 7459960608029409300}}, \'operationTime\': Timestamp(1736907656, 2)}')
unit-config-server-new-0: 02:20:57 ERROR unit.config-server-new/0.juju-log config-server:17: Failed to add shard-one-new to cluster
unit-config-server-new-0: 02:20:57 ERROR unit.config-server-new/0.juju-log config-server:17: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one-new, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one-new\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1736907656, 2), \'signature\': {\'hash\': b\'\\xa3 \\xb3FY*\\xa3\\x88"\\xe3][\\xd8\\x0bIw\\xf1\\xcd\\\\D\', \'keyId\': 7459960608029409300}}, \'operationTime\': Timestamp(1736907656, 2)}')
unit-config-server-new-0: 02:21:11 ERROR unit.config-server-new/0.juju-log config-server:17: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-config-server-new-1: 02:21:11 ERROR unit.config-server-new/1.juju-log s3-credentials:16: Failed to get pbm status: Command 'charmed-mongodb.pbm status -o json' returned non-zero exit status 1.
unit-shard-one-new-0: 02:21:22 ERROR unit.shard-one-new/0.juju-log _on_secret_remove: Secret secret:cu3hlh21geasu4t1t3a0 seems to have no observers, could be removed
unit-shard-two-new-0: 02:21:36 ERROR unit.shard-two-new/0.juju-log _on_secret_remove: Secret secret:cu3hlkq1geasu4t1t3ag seems to have no observers, could be removed
unit-config-server-new-0: 02:24:32 ERROR unit.config-server-new/0.juju-log _on_secret_remove: Secret secret:cu3hl7a1geasu4t1t39g seems to have no observers, could be removed
unit-shard-two-new-0: 02:24:32 ERROR unit.shard-two-new/0.juju-log _on_secret_remove: Secret secret:cu3hlkq1geasu4t1t3ag seems to have no observers, could be removed
unit-shard-one-new-0: 02:24:33 ERROR unit.shard-one-new/0.juju-log _on_secret_remove: Secret secret:cu3hlh21geasu4t1t3a0 seems to have no observers, could be removed
unit-config-server-new-0: 02:24:56 ERROR unit.config-server-new/0.juju-log Restore failed: Cannot restore backup, 'remap-pattern' must be set.

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...