[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one/0 [executing] active: 
  shard-one/1 [executing] active: Primary
  shard-two/0 [executing] active: Primary
  config-server/0 [executing] waiting: Waiting to sync passwords across the cluster
  config-server/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: Primary
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
  config-server/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] maintenance: backup started/running, backup id: '2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-3
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-4
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-5
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  s3-integrator/0 [idle] active: 
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: agent initialising
  config-server-new/1 [allocating] waiting: agent initialising
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: installing MongoDB
  config-server-new/1 [executing] maintenance: installing MongoDB
  shard-one-new/0 [executing] maintenance: installing MongoDB
  shard-one-new/1 [executing] maintenance: installing MongoDB
  shard-two-new/0 [executing] waiting: agent initialising
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] maintenance: starting MongoDB
  shard-two-new/0 [executing] maintenance: Installed MongoDB
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [idle] active: 
  shard-two-new/0 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] waiting: waiting to sync s3 configurations.
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] waiting: waiting to sync s3 configurations.
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: Adding shard shard-one-new to config-server
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  shard-one-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [executing] active: Primary
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: Primary
  config-server-new/0 [executing] waiting: Waiting to sync passwords across the cluster
  config-server-new/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
  config-server-new/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-15T02:12:20Z'
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:38:40Z

App                Version  Status  Scale  Charm          Channel      Rev  Exposed  Message
config-server-new  6.0.6    active      2  mongodb                       3  no       
s3-integrator               active      1  s3-integrator  latest/edge  129  no       
shard-one-new      6.0.6    active      2  mongodb                       4  no       
shard-two-new      6.0.6    active      1  mongodb                       5  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-new/0*  active    idle   6        10.239.56.229   27017-27018/tcp  Primary
config-server-new/1   active    idle   7        10.239.56.30    27017-27018/tcp  
s3-integrator/0*      active    idle   5        10.239.56.25                     
shard-one-new/0*      active    idle   8        10.239.56.167   27017/tcp        Primary
shard-one-new/1       active    idle   9        10.239.56.92    27017/tcp        
shard-two-new/0*      active    idle   10       10.239.56.148   27017/tcp        Primary

Machine  State    Address        Inst id         Base          AZ  Message
5        started  10.239.56.25   juju-53f580-5   ubuntu@22.04      Running
6        started  10.239.56.229  juju-53f580-6   ubuntu@22.04      Running
7        started  10.239.56.30   juju-53f580-7   ubuntu@22.04      Running
8        started  10.239.56.167  juju-53f580-8   ubuntu@22.04      Running
9        started  10.239.56.92   juju-53f580-9   ubuntu@22.04      Running
10       started  10.239.56.148  juju-53f580-10  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-0: 01:34:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:34:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:34:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:34:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-0: 01:34:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-1: 01:34:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:34:41 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:34:41 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:34:41 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:34:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:34:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:34:44 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:34:59 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:34:59 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:35:00 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-5: 01:35:06 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:35:06 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-s3-integrator-0: 01:35:06 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-1: 01:35:13 ERROR unit.config-server/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:35:13 ERROR unit.config-server/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:35:13 ERROR unit.config-server/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:35:13 ERROR unit.config-server/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:35:23 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:35:23 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:35:24 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:35:24 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:35:36 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:35:36 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:37:04 ERROR unit.config-server/1.juju-log s3-credentials:7: cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of backups: get storage: storage undefined"}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-1: 01:37:04 ERROR unit.config-server/1.juju-log s3-credentials:7: Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of backups: get storage: storage undefined"}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-shard-one-0: 01:38:06 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67afeffde1125747724c36b1, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.0007140359994082246>, <ServerDescription ('10.239.56.79', 27017) server_type: RSSecondary, rtt: 0.0009101680007006507>]>
unit-shard-one-0: 01:38:11 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67aff001e1125747724c36b2, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.0013778809989162255>, <ServerDescription ('10.239.56.79', 27017) server_type: RSSecondary, rtt: 0.0008762670004216488>]>
unit-shard-one-0: 01:38:43 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67aff0226fcc147cba22155c, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.0008438359982392285>, <ServerDescription ('10.239.56.79', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67afeff9b4cf86d74de0451e'), 'counter': 6}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 2768, 'lastCommittedOpTime': Timestamp(1739583497, 6), '$clusterTime': {'clusterTime': Timestamp(1739583519, 2), 'signature': {'hash': b'\\xeb\\xa696dj\\xa4\\xe2\\xc9\\xee#\\x9f2\\xddaGHJ\\xc1|', 'keyId': 7471453506721808409}}, 'operationTime': Timestamp(1739583497, 6)}")>]>
unit-shard-one-0: 01:38:47 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67aff0266fcc147cba22155d, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.0008591469995735679>, <ServerDescription ('10.239.56.79', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('10.239.56.79:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 2000.0ms, connectTimeoutMS: 2000.0ms)')>]>
unit-shard-one-0: 01:38:52 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67aff02a6fcc147cba22155e, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.000674325001455145>, <ServerDescription ('10.239.56.79', 27017) server_type: RSSecondary, rtt: 0.0009819480001169723>]>
unit-shard-one-0: 01:38:56 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67aff02f6fcc147cba22155f, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.203', 27017) server_type: RSSecondary, rtt: 0.0005845529994985554>, <ServerDescription ('10.239.56.79', 27017) server_type: RSSecondary, rtt: 0.0008514780020050239>]>
unit-shard-one-0: 01:41:15 ERROR unit.shard-one/0.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:17 ERROR unit.shard-one/0.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:19 ERROR unit.shard-one/0.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-config-server-0: 01:46:23 ERROR unit.config-server/0.juju-log cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.239.56.215:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-0: 01:46:23 ERROR unit.config-server/0.juju-log Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.239.56.215:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

machine-0: 02:17:45 ERROR juju.api.watcher error trying to stop watcher: websocket: close sent
machine-6: 02:22:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:22:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-0: 02:22:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-7: 02:22:20 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:22:20 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-1: 02:22:20 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-8: 02:22:28 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:22:28 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-0: 02:22:29 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-9: 02:22:33 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:22:33 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-1: 02:22:33 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-10: 02:22:41 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-10: 02:22:41 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-new-0: 02:22:41 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-0: 02:22:55 ERROR unit.config-server-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:22:55 ERROR unit.config-server-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:23:00 ERROR unit.config-server-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:23:00 ERROR unit.config-server-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:23:06 ERROR unit.shard-one-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:23:06 ERROR unit.shard-one-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:23:10 ERROR unit.shard-one-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:23:10 ERROR unit.shard-one-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:23:19 ERROR unit.shard-two-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:23:19 ERROR unit.shard-two-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:24:41 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affae8a964592b082fcd50, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0008908509989851154>, <ServerDescription ('10.239.56.92', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67affae25015f5c1cd59fe5f'), 'counter': 4}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 14979}")>]>
unit-shard-one-new-0: 02:24:45 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affaeca964592b082fcd51, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.001190913997561438>, <ServerDescription ('10.239.56.92', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67affae25015f5c1cd59fe5f'), 'counter': 4}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 10821}")>]>
unit-shard-one-new-0: 02:24:50 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affaf0a964592b082fcd52, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0010849049976968672>, <ServerDescription ('10.239.56.92', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67affae25015f5c1cd59fe5f'), 'counter': 4}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 6650}")>]>
unit-shard-one-new-0: 02:24:54 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affaf5a964592b082fcd53, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0012711659983324353>, <ServerDescription ('10.239.56.92', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67affae25015f5c1cd59fe5f'), 'counter': 4}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 2492}")>]>
unit-config-server-new-1: 02:24:56 ERROR unit.config-server-new/1.juju-log s3-credentials:16: cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of backups: get storage: storage undefined"}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-shard-one-new-0: 02:24:58 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affaf9a964592b082fcd54, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0022270570007094648>, <ServerDescription ('10.239.56.92', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('10.239.56.92:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 2000.0ms, connectTimeoutMS: 2000.0ms)')>]>
unit-shard-one-new-0: 02:25:02 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affafda964592b082fcd55, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0009310200002801139>, <ServerDescription ('10.239.56.92', 27017) server_type: RSSecondary, rtt: 0.0010198419986409135>]>
unit-shard-one-new-0: 02:25:06 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affb01a964592b082fcd56, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0006349079994834028>, <ServerDescription ('10.239.56.92', 27017) server_type: RSSecondary, rtt: 0.0015761190006742254>]>
unit-shard-one-new-0: 02:26:41 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affb5f127726a11070104a, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.0009619199990993366>, <ServerDescription ('10.239.56.92', 27017) server_type: RSSecondary, rtt: 0.0008100390004983637>]>
unit-shard-one-new-0: 02:26:45 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67affb64127726a11070104b, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.239.56.167', 27017) server_type: RSSecondary, rtt: 0.000895329998456873>, <ServerDescription ('10.239.56.92', 27017) server_type: RSSecondary, rtt: 0.0008650510026200209>]>
unit-config-server-new-0: 02:33:26 ERROR unit.config-server-new/0.juju-log Restore failed: Cannot restore backup, 'remap-pattern' must be set.

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...