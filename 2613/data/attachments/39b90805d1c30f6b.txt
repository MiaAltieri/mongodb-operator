[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one/0 [executing] active: Primary
  shard-one/1 [executing] active: 
  shard-two/0 [executing] active: Primary
  config-server/0 [executing] active: 
  config-server/1 [executing] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-3
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-4
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-5
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  s3-integrator/0 [idle] active: 
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [executing] maintenance: installing MongoDB
  shard-one-new/0 [executing] waiting: agent initialising
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] maintenance: Installed MongoDB
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [executing] maintenance: installing MongoDB
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: installing charm software
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: starting MongoDB
  config-server-new/1 [executing] active: 
  shard-one-new/1 [executing] maintenance: installing MongoDB
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] waiting: waiting to sync s3 configurations.
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [executing] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
  shard-two-new/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] blocked: Charm revision (1+dfeb7f0-dirty-locally built) is not up-to date with config-server.
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [executing] active: Primary
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: Primary
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/1 [idle] maintenance: restore started/running, backup id:'2025-02-13T02:22:56Z'
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:54:01Z

App                Version  Status  Scale  Charm          Channel      Rev  Exposed  Message
config-server-new  6.0.6    active      2  mongodb                       3  no       
s3-integrator               active      1  s3-integrator  latest/edge  127  no       
shard-one-new      6.0.6    active      2  mongodb                       4  no       
shard-two-new      6.0.6    active      1  mongodb                       5  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-new/0   active    idle   6        10.58.19.233    27017-27018/tcp  
config-server-new/1*  active    idle   7        10.58.19.221    27017-27018/tcp  Primary
s3-integrator/0*      active    idle   5        10.58.19.193                     
shard-one-new/0*      active    idle   8        10.58.19.56     27017/tcp        Primary
shard-one-new/1       active    idle   9        10.58.19.112    27017/tcp        
shard-two-new/0*      active    idle   10       10.58.19.5      27017/tcp        Primary

Machine  State    Address       Inst id         Base          AZ  Message
5        started  10.58.19.193  juju-a148c7-5   ubuntu@22.04      Running
6        started  10.58.19.233  juju-a148c7-6   ubuntu@22.04      Running
7        started  10.58.19.221  juju-a148c7-7   ubuntu@22.04      Running
8        started  10.58.19.56   juju-a148c7-8   ubuntu@22.04      Running
9        started  10.58.19.112  juju-a148c7-9   ubuntu@22.04      Running
10       started  10.58.19.5    juju-a148c7-10  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-1: 01:41:39 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:41:39 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-1: 01:41:39 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:41:51 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:41:51 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:41:52 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-0: 01:42:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:42:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-0: 01:42:08 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:42:11 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:42:11 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:42:11 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-1: 01:42:18 ERROR unit.config-server/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:42:18 ERROR unit.config-server/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-5: 01:42:18 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:42:18 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-s3-integrator-0: 01:42:18 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:42:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:42:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:42:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-0: 01:42:31 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:42:31 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:42:51 ERROR unit.config-server/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:42:51 ERROR unit.config-server/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:43:03 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:43:03 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:44:05 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:44:05 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:45:43 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad4ec62658ab45a36c2a26, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.145', 27017) server_type: RSSecondary, rtt: 0.0007027750002635003>, <ServerDescription ('10.58.19.221', 27017) server_type: RSSecondary, rtt: 0.0008734469997762062>]>
unit-shard-one-0: 01:45:47 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad4eca2658ab45a36c2a27, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.145', 27017) server_type: RSSecondary, rtt: 0.0007532059998993645>, <ServerDescription ('10.58.19.221', 27017) server_type: RSSecondary, rtt: 0.0006155150003905874>]>
unit-shard-one-0: 01:46:27 ERROR unit.shard-one/0.juju-log Deferring process_unremoved_units: error=ServerSelectionTimeoutError('No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad4ef168ed5e6e92b58502, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription (\'10.58.19.145\', 27017) server_type: RSSecondary, rtt: 0.0006233570002223132>, <ServerDescription (\'10.58.19.221\', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {\'topologyVersion\': {\'processId\': ObjectId(\'67ad4ec08564ea8024fb21a5\'), \'counter\': 10}, \'ok\': 0.0, \'errmsg\': \'The server is in quiesce mode and will shut down\', \'code\': 91, \'codeName\': \'ShutdownInProgress\', \'remainingQuiesceTimeMillis\': 5027, \'lastCommittedOpTime\': Timestamp(1739411174, 5), \'$clusterTime\': {\'clusterTime\': Timestamp(1739411175, 2), \'signature\': {\'hash\': b\'\\\\xb7h(\\\\xfaO,aIG\\\\x0b\\\\xc2\\\\xfb\\\\xd3\\\\xef\\\\x17!\\\\x97b\\\\xb2\\\\t\', \'keyId\': 7470713161734160409}}, \'operationTime\': Timestamp(1739411174, 5)}")>]>')
unit-config-server-1: 01:46:48 ERROR unit.config-server/1.juju-log config-server:8: cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-one` [shard-one/10.58.19.145:27017,10.58.19.221:27017]: ping: server selection error: server selection timeout, current topology: { Type: ReplicaSetNoPrimary, Servers: [{ Addr: 10.58.19.145:27017, Type: Unknown, Last error: dial tcp 10.58.19.145:27017: connect: connection refused }, { Addr: 10.58.19.221:27017, Type: RSSecondary, Average RTT: 525557 }, ] }"}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-1: 01:46:48 ERROR unit.config-server/1.juju-log config-server:8: Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-one` [shard-one/10.58.19.145:27017,10.58.19.221:27017]: ping: server selection error: server selection timeout, current topology: { Type: ReplicaSetNoPrimary, Servers: [{ Addr: 10.58.19.145:27017, Type: Unknown, Last error: dial tcp 10.58.19.145:27017: connect: connection refused }, { Addr: 10.58.19.221:27017, Type: RSSecondary, Average RTT: 525557 }, ] }"}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-shard-one-0: 01:46:52 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad4f0bd926510eba3e4b06, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.145', 27017) server_type: RSSecondary, rtt: 0.0015132409998841467>, <ServerDescription ('10.58.19.221', 27017) server_type: RSSecondary, rtt: 0.0025701599997773883>]>
unit-shard-one-0: 01:46:57 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad4f10d926510eba3e4b07, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.145', 27017) server_type: RSSecondary, rtt: 0.001250773999345256>, <ServerDescription ('10.58.19.221', 27017) server_type: RSSecondary, rtt: 0.003049582000130613>]>
unit-shard-one-0: 01:52:15 ERROR unit.shard-one/0.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:52:17 ERROR unit.shard-one/0.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:52:19 ERROR unit.shard-one/0.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-config-server-1: 01:58:24 ERROR unit.config-server/1.juju-log cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-one` [shard-one/10.58.19.145:27017,10.58.19.221:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-1: 01:58:24 ERROR unit.config-server/1.juju-log Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-one` [shard-one/10.58.19.145:27017,10.58.19.221:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

machine-7: 02:33:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:33:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-1: 02:33:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-8: 02:33:30 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:33:30 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-0: 02:33:30 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-10: 02:33:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-10: 02:33:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-new-0: 02:33:43 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-1: 02:33:52 ERROR unit.config-server-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:33:52 ERROR unit.config-server-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:34:06 ERROR unit.shard-one-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:34:06 ERROR unit.shard-one-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:34:18 ERROR unit.shard-two-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:34:18 ERROR unit.shard-two-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-6: 02:34:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:34:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-0: 02:34:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-9: 02:34:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:34:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-1: 02:34:43 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-0: 02:35:00 ERROR unit.config-server-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:35:00 ERROR unit.config-server-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:35:15 ERROR unit.shard-one-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:35:15 ERROR unit.shard-one-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:38:04 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad5b0b0df740e0d9783145, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.112', 27017) server_type: RSSecondary, rtt: 0.0009788400002435083>, <ServerDescription ('10.58.19.56', 27017) server_type: RSSecondary, rtt: 0.0008283380002467311>]>
unit-shard-one-new-0: 02:38:08 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad5b0f0df740e0d9783146, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.112', 27017) server_type: RSSecondary, rtt: 0.0007467679997716914>, <ServerDescription ('10.58.19.56', 27017) server_type: RSSecondary, rtt: 0.0008827410001686076>]>
unit-shard-one-new-0: 02:38:40 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad5b2fd1e0a3b26917af84, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.112', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67ad5b06da18536430c55d2a'), 'counter': 10}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 4208, 'lastCommittedOpTime': Timestamp(1739414295, 6), '$clusterTime': {'clusterTime': Timestamp(1739414316, 1), 'signature': {'hash': b'R\\xbd\\xa0\\xcf\\xa5\\x17.\\xfe\\xef:z,\\x87\\x9a>\\x1e{\\x0f\\xa0\\x11', 'keyId': 7470726446068006937}}, 'operationTime': Timestamp(1739414295, 6)}")>, <ServerDescription ('10.58.19.56', 27017) server_type: RSSecondary, rtt: 0.0010096209998664563>]>
unit-shard-one-new-0: 02:38:44 ERROR unit.shard-one-new/0.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67ad5b33d1e0a3b26917af85, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.58.19.112', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67ad5b06da18536430c55d2a'), 'counter': 10}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 55, 'lastCommittedOpTime': Timestamp(1739414295, 6), '$clusterTime': {'clusterTime': Timestamp(1739414316, 1), 'signature': {'hash': b'R\\xbd\\xa0\\xcf\\xa5\\x17.\\xfe\\xef:z,\\x87\\x9a>\\x1e{\\x0f\\xa0\\x11', 'keyId': 7470726446068006937}}, 'operationTime': Timestamp(1739414295, 6)}")>, <ServerDescription ('10.58.19.56', 27017) server_type: RSSecondary, rtt: 0.0008234990000346443>]>
unit-config-server-new-1: 02:49:38 ERROR unit.config-server-new/1.juju-log Restore failed: Cannot restore backup, 'remap-pattern' must be set.

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...