[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one/0 [executing] active: Primary
  shard-one/1 [executing] active: 
  shard-two/0 [executing] active: Primary
  config-server/0 [executing] active: 
  config-server/1 [executing] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/0 [idle] active: 
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] maintenance: backup started/running, backup id: '2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-3
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-4
[32mINFO    [0m juju.model:__init__.py:2301 Deploying local:jammy/mongodb-5
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  s3-integrator/0 [idle] active: 
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [allocating] waiting: waiting for machine
  config-server-new/1 [allocating] waiting: waiting for machine
  shard-one-new/0 [allocating] waiting: waiting for machine
  shard-one-new/1 [allocating] waiting: waiting for machine
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: installing charm software
  config-server-new/1 [executing] waiting: agent initialising
  shard-one-new/0 [allocating] waiting: agent initialising
  shard-one-new/1 [allocating] waiting: agent initialising
  shard-two-new/0 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] maintenance: starting MongoDB
  config-server-new/1 [executing] active: 
  shard-one-new/0 [executing] maintenance: Installed MongoDB
  shard-one-new/1 [executing] maintenance: Installed MongoDB
  shard-two-new/0 [executing] maintenance: installing MongoDB
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] active: 
  shard-one-new/0 [idle] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] active: 
  shard-two-new/0 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [executing] active: 
  config-server-new/1 [executing] waiting: waiting to sync s3 configurations.
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [executing] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] maintenance: Adding shard to config-server
  shard-two-new/0 [executing] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/0 [executing] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [executing] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [idle] maintenance: Adding shard to config-server
  shard-one-new/1 [idle] maintenance: Adding shard to config-server
  shard-two-new/0 [idle] maintenance: Adding shard to config-server
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] active: 
  config-server-new/1 [idle] active: 
  shard-one-new/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  shard-one-new/0 [executing] active: 
  shard-one-new/1 [executing] active: Primary
  shard-two-new/0 [executing] active: Primary
  config-server-new/0 [executing] waiting: Waiting to sync passwords across the cluster
  config-server-new/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] waiting: Waiting to sync passwords across the cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
  config-server-new/1 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  config-server-new/0 [idle] maintenance: restore started/running, backup id:'2025-02-19T02:07:41Z'
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:34:16Z

App                Version  Status  Scale  Charm          Channel      Rev  Exposed  Message
config-server-new  6.0.6    active      2  mongodb                       3  no       
s3-integrator               active      1  s3-integrator  latest/edge  131  no       
shard-one-new      6.0.6    active      2  mongodb                       4  no       
shard-two-new      6.0.6    active      1  mongodb                       5  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-new/0*  active    idle   6        10.138.113.92   27017-27018/tcp  Primary
config-server-new/1   active    idle   7        10.138.113.51   27017-27018/tcp  
s3-integrator/0*      active    idle   5        10.138.113.235                   
shard-one-new/0       active    idle   8        10.138.113.123  27017/tcp        
shard-one-new/1*      active    idle   9        10.138.113.112  27017/tcp        Primary
shard-two-new/0*      active    idle   10       10.138.113.8    27017/tcp        Primary

Machine  State    Address         Inst id         Base          AZ  Message
5        started  10.138.113.235  juju-1e3d54-5   ubuntu@22.04      Running
6        started  10.138.113.92   juju-1e3d54-6   ubuntu@22.04      Running
7        started  10.138.113.51   juju-1e3d54-7   ubuntu@22.04      Running
8        started  10.138.113.123  juju-1e3d54-8   ubuntu@22.04      Running
9        started  10.138.113.112  juju-1e3d54-9   ubuntu@22.04      Running
10       started  10.138.113.8    juju-1e3d54-10  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-1: 01:35:40 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:35:40 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-1: 01:35:40 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-0: 01:35:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:35:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-0: 01:35:43 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:35:45 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:35:45 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:35:46 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:35:46 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:35:46 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:35:46 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-5: 01:36:07 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:36:07 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-s3-integrator-0: 01:36:07 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:36:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:36:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:36:08 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-0: 01:36:16 ERROR unit.config-server/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:36:16 ERROR unit.config-server/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:36:22 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:36:22 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-0: 01:36:24 ERROR unit.config-server/0.juju-log This operation (update_relation_data()) can only be performed by the leader unit
unit-config-server-0: 01:36:27 ERROR unit.config-server/0.juju-log Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-config-server-1: 01:36:28 ERROR unit.config-server/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-1: 01:36:28 ERROR unit.config-server/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:36:30 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:36:30 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:36:30 ERROR unit.shard-one/1.juju-log This operation (update_relation_data()) can only be performed by the leader unit
unit-config-server-0: 01:36:30 ERROR unit.config-server/0.juju-log database-peers:0: Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-shard-one-1: 01:36:32 ERROR unit.shard-one/1.juju-log Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-config-server-0: 01:36:33 ERROR unit.config-server/0.juju-log upgrade-version-a:1: Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-shard-one-1: 01:36:34 ERROR unit.shard-one/1.juju-log database-peers:3: Deferring because of Exception Waiting for leader unit to generate keyfile contents
unit-shard-two-0: 01:36:39 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:36:39 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:39:02 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b5363511416de4cc0cd687, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.143', 27017) server_type: RSSecondary, rtt: 0.001628471999993053>, <ServerDescription ('10.138.113.38', 27017) server_type: RSSecondary, rtt: 0.0015693199998167984>]>
unit-shard-one-0: 01:39:06 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b5363911416de4cc0cd688, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.143', 27017) server_type: RSSecondary, rtt: 0.0009965559997908713>, <ServerDescription ('10.138.113.38', 27017) server_type: RSSecondary, rtt: 0.0015256770002451958>]>
unit-shard-one-0: 01:39:39 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b5365a1a79d1f8d33263ae, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.143', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67b53630e5252dd1361e68f8'), 'counter': 10}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 3606, 'lastCommittedOpTime': Timestamp(1739929154, 6), '$clusterTime': {'clusterTime': Timestamp(1739929175, 1), 'signature': {'hash': b'0\\xfb{\\xc0\\x1b\\xb4BS\\xe5)v\\xdd\\x10a\\xa2\\xd0z\\x07\\x9c\\x16', 'keyId': 7472938173836820505}}, 'operationTime': Timestamp(1739929167, 1)}")>, <ServerDescription ('10.138.113.38', 27017) server_type: RSSecondary, rtt: 0.0007541070003753703>]>
unit-shard-one-0: 01:39:43 ERROR unit.shard-one/0.juju-log sharding:8: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b5365e1a79d1f8d33263af, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.143', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('10.138.113.143:27017: [Errno 104] Connection reset by peer (configured timeouts: socketTimeoutMS: 2000.0ms, connectTimeoutMS: 2000.0ms)')>, <ServerDescription ('10.138.113.38', 27017) server_type: RSSecondary, rtt: 0.0011221539998587104>]>
unit-shard-one-0: 01:41:05 ERROR unit.shard-one/0.juju-log Backup failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:07 ERROR unit.shard-one/0.juju-log List-backups failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-shard-one-0: 01:41:09 ERROR unit.shard-one/0.juju-log Restore failed: Relation with s3-integrator charm missing, cannot restore from a backup.
unit-config-server-1: 01:42:32 ERROR unit.config-server/1.juju-log cmd failed - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.138.113.99:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

unit-config-server-1: 01:42:32 ERROR unit.config-server/1.juju-log Failed to get pbm status: cmd failed (1) - cmd=['/snap/bin/charmed-mongodb.pbm', 'status', '-o', 'json'], stdout={"Error":"get status of cluster: connect to `shard-two` [shard-two/10.138.113.99:27017]: ping: connection() error occurred during connection handshake: auth error: unable to authenticate using mechanism \"SCRAM-SHA-256\": (AuthenticationFailed) Authentication failed."}
, stderr=cmd_run.go:1276: WARNING: cannot create user data directory: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH
cmd_run.go:1281: WARNING: cannot copy user Xauthority file: cannot get the current user: getent could not be executed: exec: "getent": executable file not found in $PATH

machine-6: 02:17:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:17:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-0: 02:17:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-7: 02:17:33 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:17:33 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-new-1: 02:17:33 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-8: 02:17:45 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:17:45 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:17:45 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:17:45 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-new-1: 02:17:45 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-new-0: 02:17:45 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-10: 02:17:48 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-10: 02:17:48 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-new-0: 02:17:48 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-config-server-new-1: 02:17:59 ERROR unit.config-server-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:17:59 ERROR unit.config-server-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:18:02 ERROR unit.config-server-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-new-0: 02:18:02 ERROR unit.config-server-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-new-1: 02:18:07 ERROR unit.config-server-new/1.juju-log This operation (update_relation_data()) can only be performed by the leader unit
unit-shard-one-new-0: 02:18:12 ERROR unit.shard-one-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:18:12 ERROR unit.shard-one-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:18:14 ERROR unit.shard-one-new/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-new-1: 02:18:14 ERROR unit.shard-one-new/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:18:17 ERROR unit.shard-two-new/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-new-0: 02:18:17 ERROR unit.shard-two-new/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-new-0: 02:18:20 ERROR unit.shard-one-new/0.juju-log This operation (update_relation_data()) can only be performed by the leader unit
unit-shard-one-new-1: 02:20:26 ERROR unit.shard-one-new/1.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b53fe970397fc8abfcacda, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.112', 27017) server_type: RSSecondary, rtt: 0.0008323190004375647>, <ServerDescription ('10.138.113.123', 27017) server_type: RSSecondary, rtt: 0.0008009899993339786>]>
unit-shard-one-new-1: 02:20:30 ERROR unit.shard-one-new/1.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b53fed70397fc8abfcacdb, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.112', 27017) server_type: RSSecondary, rtt: 0.0008853279996401398>, <ServerDescription ('10.138.113.123', 27017) server_type: RSSecondary, rtt: 0.0014029840003786376>]>
unit-shard-one-new-1: 02:21:02 ERROR unit.shard-one-new/1.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b5400dbbf76884d661875b, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.112', 27017) server_type: RSSecondary, rtt: 0.0012598550001712283>, <ServerDescription ('10.138.113.123', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67b53fe430742301b78e6232'), 'counter': 10}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 4626, 'lastCommittedOpTime': Timestamp(1739931637, 6), '$clusterTime': {'clusterTime': Timestamp(1739931657, 2), 'signature': {'hash': b'\\x8ej\\xcd\\xdcy\\x87e\\xf78\\xa8\\xb0ZI\\x08O\\x1d\\xce`t\\xb7', 'keyId': 7472948881190289432}}, 'operationTime': Timestamp(1739931637, 6)}")>]>
unit-shard-one-new-1: 02:21:06 ERROR unit.shard-one-new/1.juju-log sharding:17: Unable to get primary: No replica set members match selector "Primary()", Timeout: 1.0s, Topology Description: <TopologyDescription id: 67b54011bbf76884d661875c, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('10.138.113.112', 27017) server_type: RSSecondary, rtt: 0.0009924109999701614>, <ServerDescription ('10.138.113.123', 27017) server_type: Unknown, rtt: None, error=NotPrimaryError("The server is in quiesce mode and will shut down, full error: {'topologyVersion': {'processId': ObjectId('67b53fe430742301b78e6232'), 'counter': 10}, 'ok': 0.0, 'errmsg': 'The server is in quiesce mode and will shut down', 'code': 91, 'codeName': 'ShutdownInProgress', 'remainingQuiesceTimeMillis': 451, 'lastCommittedOpTime': Timestamp(1739931637, 6), '$clusterTime': {'clusterTime': Timestamp(1739931657, 2), 'signature': {'hash': b'\\x8ej\\xcd\\xdcy\\x87e\\xf78\\xa8\\xb0ZI\\x08O\\x1d\\xce`t\\xb7', 'keyId': 7472948881190289432}}, 'operationTime': Timestamp(1739931637, 6)}")>]>
unit-config-server-new-0: 02:29:31 ERROR unit.config-server-new/0.juju-log Restore failed: Cannot restore backup, 'remap-pattern' must be set.

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...