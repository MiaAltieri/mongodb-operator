[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/0 [idle] active: Shard drained from cluster, ready for removal
  shard-two/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/0 [idle] waiting: Waiting for secrets from config-server
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/0 [idle] waiting: Waiting for secrets from config-server
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] waiting: Waiting for secrets from config-server
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  shard-two/0 [executing] active: Primary
  shard-two/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
  config-server-one/1 [idle] active: Primary
  shard-one/0 [idle] active: Primary
  shard-one/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-one/0 [idle] maintenance: Draining shard shard-two
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  config-server-one/0 [idle] active:
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  02:33:18Z

App                Version  Status  Scale  Charm    Channel  Rev  Exposed  Message
config-server-one           active      2  mongodb             0  no       
shard-one                   active      2  mongodb             1  no       
shard-three                 active      2  mongodb             3  no       

Unit                  Workload  Agent  Machine  Public address  Ports            Message
config-server-one/0   active    idle   0        10.55.107.171   27017-27018/tcp  
config-server-one/1*  active    idle   1        10.55.107.176   27017-27018/tcp  Primary
shard-one/0           active    idle   2        10.55.107.158   27017/tcp        Primary
shard-one/1*          active    idle   3        10.55.107.193   27017/tcp        
shard-three/0*        active    idle   6        10.55.107.84    27017/tcp        
shard-three/1         active    idle   7        10.55.107.80    27017/tcp        Primary

Machine  State    Address        Inst id        Base          AZ  Message
0        started  10.55.107.171  juju-7e67ea-0  ubuntu@22.04      Running
1        started  10.55.107.176  juju-7e67ea-1  ubuntu@22.04      Running
2        started  10.55.107.158  juju-7e67ea-2  ubuntu@22.04      Running
3        started  10.55.107.193  juju-7e67ea-3  ubuntu@22.04      Running
6        started  10.55.107.84   juju-7e67ea-6  ubuntu@22.04      Running
7        started  10.55.107.80   juju-7e67ea-7  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

machine-3: 01:47:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:47:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-1: 01:47:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:47:29 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:47:29 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-one-1: 01:47:29 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-1: 01:47:58 ERROR unit.shard-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:47:58 ERROR unit.shard-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-one-1: 01:48:01 ERROR unit.config-server-one/1.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-one-1: 01:48:01 ERROR unit.config-server-one/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-5: 01:49:07 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 01:49:07 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-1: 01:49:07 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-two-1: 01:49:29 ERROR unit.shard-two/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-1: 01:49:29 ERROR unit.shard-two/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-2: 01:49:30 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:49:30 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-one-0: 01:49:30 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-6: 01:49:38 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 01:49:38 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-three-0: 01:49:38 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:49:39 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:49:39 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-two-0: 01:49:39 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-one-0: 01:50:01 ERROR unit.shard-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-one-0: 01:50:01 ERROR unit.shard-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
machine-0: 01:50:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:50:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-config-server-one-0: 01:50:08 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-three-0: 01:50:09 ERROR unit.shard-three/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-three-0: 01:50:09 ERROR unit.shard-three/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:50:10 ERROR unit.shard-two/0.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-two-0: 01:50:10 ERROR unit.shard-two/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-config-server-one-0: 01:50:28 ERROR unit.config-server-one/0.juju-log Unable to set params: ['vm.max_map_count']
unit-config-server-one-0: 01:50:28 ERROR unit.config-server-one/0.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-one-1: 01:51:23 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu8q12109o6ss6fkug30 seems to have no observers, could be removed
machine-7: 01:53:12 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 01:53:12 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-shard-three-1: 01:53:12 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-shard-three-1: 01:53:31 ERROR unit.shard-three/1.juju-log Unable to set params: ['vm.max_map_count']
unit-shard-three-1: 01:53:31 ERROR unit.shard-three/1.juju-log Error setting values on sysctl: Unable to set params: ['vm.max_map_count']
unit-shard-two-1: 01:55:43 ERROR unit.shard-two/1.juju-log _on_secret_remove: Secret secret:cu8q33109o6ss6fkug3g seems to have no observers, could be removed
unit-config-server-one-1: 01:58:11 ERROR unit.config-server-one/1.juju-log _on_secret_remove: Secret secret:cu8q47h09o6ss6fkug40 seems to have no observers, could be removed
unit-shard-three-0: 01:59:42 ERROR unit.shard-three/0.juju-log _on_secret_remove: Secret secret:cu8q4up09o6ss6fkug4g seems to have no observers, could be removed
unit-config-server-one-1: 02:01:48 ERROR unit.config-server-one/1.juju-log config-server:10: Failed to add shard shard-three to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1737597708, 1), 'signature': {'hash': b'9\\xca9v\\x97\\x97{L\\x01\\x12@e\\xe2q\\xbf?p\\xca\\xaf\\xee', 'keyId': 7462924341622079506}}, 'operationTime': Timestamp(1737597708, 1)}")
unit-config-server-one-1: 02:01:48 ERROR unit.config-server-one/1.juju-log config-server:10: Failed to add shard shard-one to the config server, error=OperationFailure("Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1737597708, 1), 'signature': {'hash': b'9\\xca9v\\x97\\x97{L\\x01\\x12@e\\xe2q\\xbf?p\\xca\\xaf\\xee', 'keyId': 7462924341622079506}}, 'operationTime': Timestamp(1737597708, 1)}")
unit-config-server-one-1: 02:01:48 ERROR unit.config-server-one/1.juju-log config-server:10: shard-one shard does not have the same auth as the config server.
unit-config-server-one-1: 02:02:05 ERROR unit.config-server-one/1.juju-log config-server:8: Failed to add shard shard-one to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1737597725, 1), \'signature\': {\'hash\': b\'&\\xa0O*zlJ\\xed\\x00\\xf6Y\\x15\\x03:Z\\x7f\\xb7j(\\x01\', \'keyId\': 7462924341622079506}}, \'operationTime\': Timestamp(1737597725, 1)}')
unit-config-server-one-1: 02:02:17 ERROR unit.config-server-one/1.juju-log config-server:8: Failed to add shard-one to cluster
unit-config-server-one-1: 02:02:17 ERROR unit.config-server-one/1.juju-log config-server:8: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-one, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-one\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1737597725, 1), \'signature\': {\'hash\': b\'&\\xa0O*zlJ\\xed\\x00\\xf6Y\\x15\\x03:Z\\x7f\\xb7j(\\x01\', \'keyId\': 7462924341622079506}}, \'operationTime\': Timestamp(1737597725, 1)}')
unit-shard-three-0: 02:02:27 ERROR unit.shard-three/0.juju-log _on_secret_remove: Secret secret:cu8q4up09o6ss6fkug4g seems to have no observers, could be removed
unit-shard-one-1: 02:02:30 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu8q12109o6ss6fkug30 seems to have no observers, could be removed
unit-config-server-one-1: 02:02:48 ERROR unit.config-server-one/1.juju-log config-server:9: Failed to add shard shard-two to the config server, error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-two, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-two\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1737597767, 7), \'signature\': {\'hash\': b\'\\xec+\\xd8\\xeeE\\xd0X\\x95M\\xd8\\x94\\xbba%\\xb6ZP\\xeb\\xa8\\x9e\', \'keyId\': 7462924341622079506}}, \'operationTime\': Timestamp(1737597767, 7)}')
unit-config-server-one-1: 02:02:48 ERROR unit.config-server-one/1.juju-log config-server:9: Failed to add shard-two to cluster
unit-config-server-one-1: 02:02:48 ERROR unit.config-server-one/1.juju-log config-server:9: Deferring _on_relation_event for shards interface since: error=OperationFailure('Could not find host matching read preference { mode: "primary" } for set shard-two, full error: {\'ok\': 0.0, \'errmsg\': \'Could not find host matching read preference { mode: "primary" } for set shard-two\', \'code\': 133, \'codeName\': \'FailedToSatisfyReadPreference\', \'$clusterTime\': {\'clusterTime\': Timestamp(1737597767, 7), \'signature\': {\'hash\': b\'\\xec+\\xd8\\xeeE\\xd0X\\x95M\\xd8\\x94\\xbba%\\xb6ZP\\xeb\\xa8\\x9e\', \'keyId\': 7462924341622079506}}, \'operationTime\': Timestamp(1737597767, 7)}')
unit-shard-two-1: 02:03:10 ERROR unit.shard-two/1.juju-log _on_secret_remove: Secret secret:cu8q33109o6ss6fkug3g seems to have no observers, could be removed
unit-shard-three-0: 02:07:53 ERROR unit.shard-three/0.juju-log _on_secret_remove: Secret secret:cu8q4up09o6ss6fkug4g seems to have no observers, could be removed
unit-shard-one-1: 02:07:53 ERROR unit.shard-one/1.juju-log _on_secret_remove: Secret secret:cu8q12109o6ss6fkug30 seems to have no observers, could be removed
unit-shard-two-1: 02:07:53 ERROR unit.shard-two/1.juju-log _on_secret_remove: Secret secret:cu8q33109o6ss6fkug3g seems to have no observers, could be removed
unit-config-server-one-1: 02:07:53 ERROR unit.config-server-one/1.juju-log _on_secret_remove: Secret secret:cu8q47h09o6ss6fkug40 seems to have no observers, could be removed

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...